import os
import json
import re
import time
from flask import Flask, request, jsonify
from flask_cors import CORS
import google.generativeai as genai
from google.api_core import exceptions
import chromadb

app = Flask(__name__)
CORS(app)

# --- 1. ุฅุนุฏุงุฏุงุช ุฌูุฌู Gemini ---
GOOGLE_API_KEY = os.environ.get("GEMINI_API_KEY")
genai.configure(api_key=GOOGLE_API_KEY)
EMBEDDING_MODEL = 'models/embedding-001'

def get_model_name():
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        for m in models:
            if '1.5-flash' in m: return m
        return models[0] if models else "models/gemini-1.5-flash"
    except:
        return "models/gemini-1.5-flash"

MODEL_NAME = get_model_name()

# --- 2. ุชุญููู ุงูููุชุจุฉ ูุชููุฆุฉ ChromaDB (ุงูุทุฑููุฉ ุงูุฌุฏูุฏุฉ) ---
all_knowledge = []
KB_PATH = "library_knowledge"
chroma_collection = None
is_db_initialized = False ### ูุชุบูุฑ ุฌุฏูุฏ ูุชุชุจุน ุงูุญุงูุฉ

def initialize_knowledge_base():
    """
    ุชููู ุจุจูุงุก ูุงุนุฏุฉ ุงูุจูุงูุงุช ุนูุฏ ุงูุญุงุฌุฉ ููุท (Lazy Loading).
    """
    global all_knowledge, chroma_collection, is_db_initialized

    # ุฅุฐุง ูุงูุช ูุงุนุฏุฉ ุงูุจูุงูุงุช ุฌุงูุฒุฉุ ูุง ุชูุนู ุดูุฆุงู
    if is_db_initialized:
        print("โ ูุงุนุฏุฉ ุงูุจูุงูุงุช ุฌุงูุฒุฉ ุจุงููุนู.")
        return

    print("๐ ุจุฏุก ุจูุงุก ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงูุฏูุงููุฉ ูุฃูู ูุฑุฉ... ูุฐุง ุณูุณุชุบุฑู ููุชุงู.")
    start_time = time.time()

    # 1. ุชุญููู ูููุงุช JSON
    all_knowledge = []
    if os.path.exists(KB_PATH):
        for filename in sorted(os.listdir(KB_PATH)):
            if filename.endswith(".json"):
                with open(os.path.join(KB_PATH, filename), "r", encoding="utf-8") as f:
                    all_knowledge.extend(json.load(f))
    
    if not all_knowledge:
        print("โ๏ธ ูู ูุชู ุงูุนุซูุฑ ุนูู ูููุงุช ูุนุฑูุฉ.")
        is_db_initialized = True # ููุน ุฅุนุงุฏุฉ ุงููุญุงููุฉ
        return

    # 2. ุชููุฆุฉ ChromaDB
    chroma_client = chromadb.Client()
    try:
        chroma_client.delete_collection("knowledge_base")
    except:
        pass
    chroma_collection = chroma_client.create_collection("knowledge_base")

    # 3. ุฅุถุงูุฉ ุงูุจูุงูุงุช
    documents = [unit.get("content", "") for unit in all_knowledge]
    metadatas = [{
        "author": unit.get("author", "--"),
        "book": unit.get("book", "--"),
        "part": unit.get("part", "--"),
        "page_pdf": str(unit.get("page_pdf", "--"))
    } for unit in all_knowledge]
    ids = [unit.get("unit_id", f"id_{i}") for i, unit in enumerate(all_knowledge)]

    batch_size = 50 # ุชูููู ุญุฌู ุงูุฏูุนุฉ ูุชุฌูุจ ุงูุฃุฎุทุงุก
    for i in range(0, len(documents), batch_size):
        batch_docs = documents[i:i+batch_size]
        response = genai.embed_content(model=EMBEDDING_MODEL, content=batch_docs)
        embeddings = response["embedding"]
        
        chroma_collection.add(
            ids=ids[i:i+batch_size],
            embeddings=embeddings,
            documents=batch_docs,
            metadatas=metadatas[i:i+batch_size]
        )
        print(f"โ ุชูุช ูุนุงูุฌุฉ {min(i + batch_size, len(documents))} ูู ุฃุตู {len(documents)} ูุญุฏุฉ.")

    end_time = time.time()
    print(f"๐ ุงูุชูู ุจูุงุก ูุงุนุฏุฉ ุงูุจูุงูุงุช ูู {end_time - start_time:.2f} ุซุงููุฉ.")
    is_db_initialized = True

### ### ุงูุชุนุฏูู ุงูุฃูู: ูุง ุชุณุชุฏุนู ุงูุฏุงูุฉ ุนูุฏ ุจุฏุก ุงูุชุดุบูู!
# initialize_knowledge_base() 

# --- 3. ูุญุฑู ุงูุจุญุซ ุงูุฏูุงูู ---
def semantic_search(query, collection, n_results=6):
    if not collection:
        return []
    response = genai.embed_content(model=EMBEDDING_MODEL, content=query)
    query_embedding = response["embedding"]
    results = collection.query(query_embeddings=[query_embedding], n_results=n_results)
    
    final_results = []
    for i in range(len(results['ids'][0])):
        final_results.append({
            "unit_id": results['ids'][0][i],
            "content": results['documents'][0][i],
            "author": results['metadatas'][0][i]['author'],
            "book": results['metadatas'][0][i]['book'],
            "part": results['metadatas'][0][i]['part'],
            "page_pdf": int(results['metadatas'][0][i]['page_pdf'])
        })
    return final_results

# --- 4. ููุทุฉ ุงูุงุชุตุงู (ูุน ุงูุชููุฆุฉ ุนูุฏ ุงูุทูุจ) ---
@app.route('/ask', methods=['POST'])
def ask():
    try:
        ### ### ุงูุชุนุฏูู ุงูุซุงูู: ุงุณุชุฏุนุงุก ุงูุชููุฆุฉ ููุง ###
        # ูุจู ุงูุจุญุซุ ุชุฃูุฏ ูู ุฃู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุฌุงูุฒุฉ
        initialize_knowledge_base()

        data = request.json
        user_query = data.get("question")
        if not user_query: return jsonify({"answer": "ูู ูุตู ุณุคุงู."}), 400

        results = semantic_search(user_query, chroma_collection, n_results=6)
        
        if not results: return jsonify({"answer": "ุนุฐุฑุงูุ ูู ุฃุฌุฏ ูุฐู ุงููุนูููุฉ ูู ุงูููุชุจุฉ."})

        ctx_text = ""
        for i, u in enumerate(results):
            ctx_text += f"\n--- [ูุนุฑู ุงููุฑุฌุน: {i+1}] ---\nุงููุคูู: {u.get('author','--')} | ุงููุชุงุจ: {u.get('book','--')} | ุฌ: {u.get('part','--')} | ุต: {u.get('page_pdf','--')}\nุงููุต: {u['content']}\n"
        
        prompt = f"""ุจุตูุชู ุจุงุญุซุงู ุฃูุงุฏูููุงู ูู ููุฑ ุงูุฃุณุชุงุฐ ุงูุฏูุชูุฑ ุนุจุฏ ุงูุฑุญูู ุงูุญุงุฌ ุตุงูุญุ ูุงุณุชูุงุฏุงู ุฅูู ุงููููุฌูุฉ ุงููุณุงููุฉ ุงูุงุณุชูุฑุงุฆูุฉ ูู ุชุญููู ุงููุชูู ุงููุฑููุฉุ ุฅูููู ุนุฑุถุงู ููุซูุงู ููุฃุตูู ุงูุนูููุฉ ุฑุฏุงู ุนูู ุณุคุงููู:
        ูููุชู ุตูุงุบุฉ ุฅุฌุงุจุฉ 'ุดุงููุฉ'ุ 'ููุณุนุฉ'ุ ู 'ูุฑุชุจุฉ' ููู ุงูุดุฑูุท ุงูุตุงุฑูุฉ ุงูุชุงููุฉ:
        1. ุงูุนุจุงุฑุฉ ุงูุงุณุชููุงููุฉ: ุงุจุฏุฃ ุงูุฅุฌุงุจุฉ ุญุตุฑุงู ุจู: "ุจุตูุชู ุจุงุญุซุงู ุฃูุงุฏูููุงู ูู ููุฑ ุงูุฃุณุชุงุฐ ุงูุฏูุชูุฑ ุนุจุฏ ุงูุฑุญูู ุงูุญุงุฌ ุตุงูุญุ ูุงุณุชูุงุฏุงู ุฅูู ุงููููุฌูุฉ ุงููุณุงููุฉ ุงูุงุณุชูุฑุงุฆูุฉ ูู ุชุญููู ุงููุชูู ุงููุฑููุฉุ ุฅูููู ุนุฑุถุงู ููุซูุงู ููุฃุตูู ุงูุนูููุฉ ุฑุฏุงู ุนูู ุณุคุงููู:"
        2. ุงูุงุณุชูุตุงุก: ุงุจุญุซ ุนู ูู ุงูููุงุท ูุงูุชูุงุตูู (1ุ 2ุ 3ุ 4...) ุงููุงุฑุฏุฉ ูู ุงููุตูุต ุงููุฑููุฉ ููุง ุชูุชูู ุจุงูููุฎุต. ุงููู ูู ููููู ูุน ุดุฑุญู ุงูุญุฑูู ููุง ูุฑุฏ.
        3. ุงูููู ุงูุญุฑูู: ุงููู ุงูุฌูู ุญุฑููุงู ููุง ูุฑุฏุช ูู ุงููุฑุฌุนุ ูุถุน ูู ูุต ููููู ุจูู ุนูุงูุชู ุชูุตูุต ูุฒุฏูุฌุฉ "" ูุชุจูุนุงู ุจุฑูู ูุฑุฌุน ูุชุณูุณู [1]ุ ุซู [2]ุ ูููุฐุง.
        4. ุงูุชุฑููู ุงููุชุณูุณู: ูุฌุจ ุฃู ูููู ุชุฑููู ุงููุฑุงุฌุน ูู ุงููุชู ูุชุณูุณูุงู ุชุตุงุนุฏูุงู (1ุ 2ุ 3...) ุญุณุจ ุธููุฑูุง ูู ุฅุฌุงุจุชู.
        5. ูููู ุงูููุฑุงุช: ุงุจุฏุฃ ูู ููุทุฉ ุฃู ููุฑุฉ ุฌุฏูุฏุฉ ูู ุณุทุฑ ุฌุฏูุฏ ุชูุงูุงู. ุงุณุชุฎุฏู ุงูุนูุงููู ุงููุฑุนูุฉ ุฅุฐุง ูุงูุช ููุฌูุฏุฉ ูู ุงููุต.
        6. ุงูุญุงุดูุฉ: ูู ููุงูุฉ ุงูุฅุฌุงุจุฉุ ุงูุชุจ ุนููุงูุงู ุจุงุฑุฒุงู (ุงููุฑุงุฌุน:) ุซู ุณุฑุฏ ุงููุฑุงุฌุน ุจุงูุตูุบุฉ: ุฑูู ุงููุฑุฌุน- ุงุณู ุงููุคููุ ุงุณู ุงููุชุงุจุ ุงูุฌุฒุกุ ุต: ุฑูู ุงูุตูุญุฉ.
        7. ุงูุตุฑุงูุฉ: ููููุน ุชูุงูุงู ุฅุถุงูุฉ ุฃู ูุนูููุฉ ุฎุงุฑุฌูุฉ.
        ุงููุงุฏุฉ ุงูุนูููุฉ ุงููุชุงุญุฉ:
        {ctx_text}
        ุณุคุงู ุงูุจุงุญุซ:
        {user_query}
        """

        model = genai.GenerativeModel(model_name=MODEL_NAME)
        
        for _ in range(3):
            try:
                response = model.generate_content(prompt, generation_config={"temperature": 0.0})
                return jsonify({"answer": response.text})
            except exceptions.TooManyRequests:
                time.sleep(15)
        
        return jsonify({"answer": "โ๏ธ ุงูุฎุงุฏู ูุฒุฏุญูุ ูุฑุฌู ุงููุญุงููุฉ ูุฑุฉ ุฃุฎุฑู."})

    except Exception as e:
        return jsonify({"answer": f"โ ุฎุทุฃ ุชููู: {str(e)}"}), 500

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=int(os.environ.get("PORT", 10000)))

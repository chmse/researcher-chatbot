import os
import json
import re
import time
import threading
from flask import Flask, request, jsonify
from flask_cors import CORS
import google.generativeai as genai
from google.api_core import exceptions
import chromadb

app = Flask(__name__)
CORS(app)

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¬ÙˆØ¬Ù„ Gemini ---
GOOGLE_API_KEY = os.environ.get("GEMINI_API_KEY")
if not GOOGLE_API_KEY:
    raise ValueError("GEMINI_API_KEY environment variable not set.")
genai.configure(api_key=GOOGLE_API_KEY)
EMBEDDING_MODEL = 'models/embedding-001'

def get_model_name():
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        for m in models:
            if '1.5-flash' in m: return m
        return models[0] if models else "models/gemini-1.5-flash"
    except:
        return "models/gemini-1.5-flash"

MODEL_NAME = get_model_name()

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø© ÙˆØªÙ‡ÙŠØ¦Ø© ChromaDB (Ù†Ø³Ø®Ø© Ù…ØªÙŠÙ†Ø© ÙˆØ¢Ù…Ù†Ø©) ---
all_knowledge = []
KB_PATH = "library_knowledge"
chroma_collection = None
db_status = 'not_started' # 'not_started', 'initializing', 'ready', 'failed'
db_lock = threading.Lock() # Ù‚ÙÙ„ Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©

def initialize_knowledge_base():
    """
    ØªÙ‚ÙˆÙ… Ø¨Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© ÙÙ‚Ø· (Lazy Loading) Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¢Ù…Ù†Ø©.
    """
    global all_knowledge, chroma_collection, db_status

    with db_lock:
        if db_status == 'ready':
            print("âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø§Ù‡Ø²Ø© Ø¨Ø§Ù„ÙØ¹Ù„.")
            return
        if db_status == 'initializing':
            print("â³ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø¬Ø§Ø±ÙŠØ© Ø¨Ø§Ù„ÙØ¹Ù„ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...")
            # Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ØªÙƒØªÙ…Ù„ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            while db_status == 'initializing':
                time.sleep(1)
            return

        # Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ‡ÙŠØ¦Ø©
        db_status = 'initializing'
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ù„Ø£ÙˆÙ„ Ù…Ø±Ø©... Ù‡Ø°Ø§ Ø³ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªØ§Ù‹.")

    try:
        start_time = time.time()

        # 1. ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª JSON
        all_knowledge = []
        if os.path.exists(KB_PATH):
            for filename in sorted(os.listdir(KB_PATH)):
                if filename.endswith(".json"):
                    with open(os.path.join(KB_PATH, filename), "r", encoding="utf-8") as f:
                        all_knowledge.extend(json.load(f))
        
        if not all_knowledge:
            print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ù…Ø¹Ø±ÙØ©. Ù„Ù† ØªØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
            with db_lock:
                db_status = 'failed' # Ø§Ù„ÙØ´Ù„ Ù„Ø£Ù† Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª
            return

        # 2. ØªÙ‡ÙŠØ¦Ø© ChromaDB (ØµØ±ÙŠØ­Ø§Ù‹ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ø®Ø·Ø© Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©)
        chroma_client = chromadb.Client()
        try:
            chroma_client.delete_collection("knowledge_base")
        except:
            pass
        chroma_collection = chroma_client.create_collection("knowledge_base")

        # 3. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        documents = [unit.get("content", "") for unit in all_knowledge]
        metadatas = [{
            "author": unit.get("author", "--"),
            "book": unit.get("book", "--"),
            "part": unit.get("part", "--"),
            "page_pdf": str(unit.get("page_pdf", "--")) # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù‡ ÙƒÙ†Øµ Ù…Ø¤Ù‚ØªØ§Ù‹
        } for unit in all_knowledge]
        ids = [unit.get("unit_id", f"id_{i}") for i, unit in enumerate(all_knowledge)]

        batch_size = 50
        for i in range(0, len(documents), batch_size):
            batch_docs = documents[i:i+batch_size]
            
            # Ø¥ØµÙ„Ø§Ø­ 1: Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ø¢Ù…Ù† Ù…Ø¹ Ø§Ø³ØªØ¬Ø§Ø¨Ø© API
            try:
                response = genai.embed_content(model=EMBEDDING_MODEL, content=batch_docs)
                embeddings = response.get("embedding", response.get("embeddings"))
                if not embeddings:
                    raise ValueError("Embeddings not found in API response.")
            except Exception as e:
                print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª: {e}")
                with db_lock:
                    db_status = 'failed'
                return
            
            # Ø¥ØµÙ„Ø§Ø­ 7: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø¯ÙØ¹Ø§Øª
            if len(embeddings) != len(batch_docs):
                print(f"âŒ Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ ÙÙŠ Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø©: {len(embeddings)} embeddings vs {len(batch_docs)} docs.")
                with db_lock:
                    db_status = 'failed'
                return

            chroma_collection.add(
                ids=ids[i:i+batch_size],
                embeddings=embeddings,
                documents=batch_docs,
                metadatas=metadatas[i:i+batch_size]
            )
            print(f"âœ… ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© {min(i + batch_size, len(documents))} Ù…Ù† Ø£ØµÙ„ {len(documents)} ÙˆØ­Ø¯Ø©.")

        end_time = time.time()
        print(f"ğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ {end_time - start_time:.2f} Ø«Ø§Ù†ÙŠØ©.")
        with db_lock:
            db_status = 'ready'

    except Exception as e:
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ø§Ù… Ø£Ø«Ù†Ø§Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        with db_lock:
            db_status = 'failed'

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ---
def semantic_search(query, collection, n_results=6):
    if not collection or db_status != 'ready':
        return []
    response = genai.embed_content(model=EMBEDDING_MODEL, content=query)
    query_embedding = response.get("embedding", response.get("embeddings"))
    if not query_embedding:
        print("âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ¬Ù‡ Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù….")
        return []
        
    results = collection.query(query_embeddings=[query_embedding], n_results=n_results)
    
    final_results = []
    for i in range(len(results['ids'][0])):
        # Ø¥ØµÙ„Ø§Ø­ 2: Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¢Ù…Ù† Ù„Ù€ page_pdf
        page_pdf_str = results['metadatas'][0][i].get('page_pdf', '--')
        try:
            page_pdf_int = int(page_pdf_str)
        except (ValueError, TypeError):
            page_pdf_int = 0 # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©

        final_results.append({
            "unit_id": results['ids'][0][i],
            "content": results['documents'][0][i],
            "author": results['metadatas'][0][i].get('author', '--'),
            "book": results['metadatas'][0][i].get('book', '--'),
            "part": results['metadatas'][0][i].get('part', '--'),
            "page_pdf": page_pdf_int
        })
    return final_results

# --- 4. Ù†Ù‚Ø·Ø© Ø§Ù„Ø§ØªØµØ§Ù„ (Ù…Ø¹ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø§Ù„Ø©) ---
@app.route('/ask', methods=['POST'])
def ask():
    try:
        # Ø¥ØµÙ„Ø§Ø­ 3 Ùˆ 6: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡
        if db_status == 'failed':
            return jsonify({"answer": "âŒ ÙØ´Ù„Øª ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©. ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø®Ø§Ø¯Ù…."}), 503

        initialize_knowledge_base()

        if db_status != 'ready':
             return jsonify({"answer": "â³ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù‚ÙŠØ¯ Ø§Ù„ØªØ¬Ù‡ÙŠØ² Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¹Ø¯ Ù‚Ù„ÙŠÙ„."}), 503

        data = request.json
        user_query = data.get("question")
        if not user_query: return jsonify({"answer": "Ù„Ù… ÙŠØµÙ„ Ø³Ø¤Ø§Ù„."}), 400

        results = semantic_search(user_query, chroma_collection, n_results=6)
        
        if not results: return jsonify({"answer": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©."})

        ctx_text = ""
        for i, u in enumerate(results):
            ctx_text += f"\n--- [Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø±Ø¬Ø¹: {i+1}] ---\nØ§Ù„Ù…Ø¤Ù„Ù: {u.get('author','--')} | Ø§Ù„ÙƒØªØ§Ø¨: {u.get('book','--')} | Ø¬: {u.get('part','--')} | Øµ: {u.get('page_pdf','--')}\nØ§Ù„Ù†Øµ: {u['content']}\n"
        
        prompt = f"""Ø¨ØµÙØªÙŠ Ø¨Ø§Ø­Ø«Ø§Ù‹ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ§Ù‹ ÙÙŠ ÙÙƒØ± Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø¯ÙƒØªÙˆØ± Ø¹Ø¨Ø¯ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø­Ø§Ø¬ ØµØ§Ù„Ø­ØŒ ÙˆØ§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ù„Ø³Ø§Ù†ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø¦ÙŠØ© ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙˆÙ† Ø§Ù„Ù…Ø±ÙÙ‚Ø©ØŒ Ø¥Ù„ÙŠÙƒÙ… Ø¹Ø±Ø¶Ø§Ù‹ Ù…ÙˆØ«Ù‚Ø§Ù‹ Ù„Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø±Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ÙƒÙ…:
        Ù…Ù‡Ù…ØªÙƒ ØµÙŠØ§ØºØ© Ø¥Ø¬Ø§Ø¨Ø© 'Ø´Ø§Ù…Ù„Ø©'ØŒ 'Ù…ÙˆØ³Ø¹Ø©'ØŒ Ùˆ 'Ù…Ø±ØªØ¨Ø©' ÙˆÙÙ‚ Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„ØµØ§Ø±Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:
        1. Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ù„ÙŠØ©: Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø­ØµØ±Ø§Ù‹ Ø¨Ù€: "Ø¨ØµÙØªÙŠ Ø¨Ø§Ø­Ø«Ø§Ù‹ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ§Ù‹ ÙÙŠ ÙÙƒØ± Ø§Ù„Ø£Ø³ØªØ§Ø° Ø§Ù„Ø¯ÙƒØªÙˆØ± Ø¹Ø¨Ø¯ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø­Ø§Ø¬ ØµØ§Ù„Ø­ØŒ ÙˆØ§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ù„Ø³Ø§Ù†ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø¦ÙŠØ© ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙˆÙ† Ø§Ù„Ù…Ø±ÙÙ‚Ø©ØŒ Ø¥Ù„ÙŠÙƒÙ… Ø¹Ø±Ø¶Ø§Ù‹ Ù…ÙˆØ«Ù‚Ø§Ù‹ Ù„Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø±Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ÙƒÙ…:"
        2. Ø§Ù„Ø§Ø³ØªÙ‚ØµØ§Ø¡: Ø§Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„ (1ØŒ 2ØŒ 3ØŒ 4...) Ø§Ù„ÙˆØ§Ø±Ø¯Ø© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ÙÙ‚Ø© ÙˆÙ„Ø§ ØªÙƒØªÙÙ Ø¨Ø§Ù„Ù…Ù„Ø®Øµ. Ø§Ù†Ù‚Ù„ ÙƒÙ„ Ù…ÙÙ‡ÙˆÙ… Ù…Ø¹ Ø´Ø±Ø­Ù‡ Ø§Ù„Ø­Ø±ÙÙŠ ÙƒÙ…Ø§ ÙˆØ±Ø¯.
        3. Ø§Ù„Ù†Ù‚Ù„ Ø§Ù„Ø­Ø±ÙÙŠ: Ø§Ù†Ù‚Ù„ Ø§Ù„Ø¬Ù…Ù„ Ø­Ø±ÙÙŠØ§Ù‹ ÙƒÙ…Ø§ ÙˆØ±Ø¯Øª ÙÙŠ Ø§Ù„Ù…Ø±Ø¬Ø¹ØŒ ÙˆØ¶Ø¹ ÙƒÙ„ Ù†Øµ Ù…Ù†Ù‚ÙˆÙ„ Ø¨ÙŠÙ† Ø¹Ù„Ø§Ù…ØªÙŠ ØªÙ†ØµÙŠØµ Ù…Ø²Ø¯ÙˆØ¬Ø© "" Ù…ØªØ¨ÙˆØ¹Ø§Ù‹ Ø¨Ø±Ù‚Ù… Ù…Ø±Ø¬Ø¹ Ù…ØªØ³Ù„Ø³Ù„ [1]ØŒ Ø«Ù… [2]ØŒ ÙˆÙ‡ÙƒØ°Ø§.
        4. Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙÙŠ Ø§Ù„Ù…ØªÙ† Ù…ØªØ³Ù„Ø³Ù„Ø§Ù‹ ØªØµØ§Ø¹Ø¯ÙŠØ§Ù‹ (1ØŒ 2ØŒ 3...) Ø­Ø³Ø¨ Ø¸Ù‡ÙˆØ±Ù‡Ø§ ÙÙŠ Ø¥Ø¬Ø§Ø¨ØªÙƒ.
        5. Ù‡ÙŠÙƒÙ„ Ø§Ù„ÙÙ‚Ø±Ø§Øª: Ø§Ø¨Ø¯Ø£ ÙƒÙ„ Ù†Ù‚Ø·Ø© Ø£Ùˆ ÙÙƒØ±Ø© Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯ ØªÙ…Ø§Ù…Ø§Ù‹. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†Øµ.
        6. Ø§Ù„Ø­Ø§Ø´ÙŠØ©: ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ø§ÙƒØªØ¨ Ø¹Ù†ÙˆØ§Ù†Ø§Ù‹ Ø¨Ø§Ø±Ø²Ø§Ù‹ (Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹:) Ø«Ù… Ø³Ø±Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø¨Ø§Ù„ØµÙŠØºØ©: Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹- Ø§Ø³Ù… Ø§Ù„Ù…Ø¤Ù„ÙØŒ Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ØŒ Ø§Ù„Ø¬Ø²Ø¡ØŒ Øµ: Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©.
        7. Ø§Ù„ØµØ±Ø§Ù…Ø©: Ù…Ù…Ù†ÙˆØ¹ ØªÙ…Ø§Ù…Ø§Ù‹ Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø®Ø§Ø±Ø¬ÙŠØ©.
        Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©:
        {ctx_text}
        Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¨Ø§Ø­Ø«:
        {user_query}
        """

        model = genai.GenerativeModel(model_name=MODEL_NAME)
        
        for _ in range(3):
            try:
                response = model.generate_content(prompt, generation_config={"temperature": 0.0})
                return jsonify({"answer": response.text})
            except exceptions.TooManyRequests:
                time.sleep(15)
        
        return jsonify({"answer": "âš ï¸ Ø§Ù„Ø®Ø§Ø¯Ù… Ù…Ø²Ø¯Ø­Ù…ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."})

    except Exception as e:
        app.logger.error(f"An error occurred in /ask: {e}", exc_info=True)
        return jsonify({"answer": f"âŒ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}"}), 500

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=int(os.environ.get("PORT", 10000)))
